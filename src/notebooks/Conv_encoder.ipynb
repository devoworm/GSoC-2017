{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import python.edge as edge \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files= '../data/interim/s7_spim3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = [img_to_array(load_img(file, grayscale=True, target_size=(28,28)))\n",
    " for file in glob.glob(files+\"*.jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(images)\n",
    "x_test =np.array(images)[275:345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 70 samples\n",
      "Epoch 1/600\n",
      "500/500 [==============================] - 2s - loss: 0.6674 - val_loss: 0.5142\n",
      "Epoch 2/600\n",
      "500/500 [==============================] - 2s - loss: 0.3556 - val_loss: 0.4377\n",
      "Epoch 3/600\n",
      "500/500 [==============================] - 1s - loss: 0.3005 - val_loss: 0.3676\n",
      "Epoch 4/600\n",
      "500/500 [==============================] - 2s - loss: 0.2577 - val_loss: 0.3232\n",
      "Epoch 5/600\n",
      "500/500 [==============================] - 2s - loss: 0.2319 - val_loss: 0.3066\n",
      "Epoch 6/600\n",
      "500/500 [==============================] - 2s - loss: 0.2237 - val_loss: 0.2991\n",
      "Epoch 7/600\n",
      "500/500 [==============================] - 1s - loss: 0.2175 - val_loss: 0.2936\n",
      "Epoch 8/600\n",
      "500/500 [==============================] - 1s - loss: 0.2187 - val_loss: 0.2897\n",
      "Epoch 9/600\n",
      "500/500 [==============================] - 1s - loss: 0.2129 - val_loss: 0.2866\n",
      "Epoch 10/600\n",
      "500/500 [==============================] - 1s - loss: 0.2115 - val_loss: 0.2858\n",
      "Epoch 11/600\n",
      "500/500 [==============================] - 2s - loss: 0.2103 - val_loss: 0.2831\n",
      "Epoch 12/600\n",
      "500/500 [==============================] - 2s - loss: 0.2081 - val_loss: 0.2807\n",
      "Epoch 13/600\n",
      "500/500 [==============================] - 1s - loss: 0.2093 - val_loss: 0.2827\n",
      "Epoch 14/600\n",
      "500/500 [==============================] - 2s - loss: 0.2077 - val_loss: 0.2796\n",
      "Epoch 15/600\n",
      "500/500 [==============================] - 1s - loss: 0.2058 - val_loss: 0.2790\n",
      "Epoch 16/600\n",
      "500/500 [==============================] - 2s - loss: 0.2057 - val_loss: 0.2793\n",
      "Epoch 17/600\n",
      "500/500 [==============================] - 2s - loss: 0.2071 - val_loss: 0.2775\n",
      "Epoch 18/600\n",
      "500/500 [==============================] - 1s - loss: 0.2041 - val_loss: 0.2774\n",
      "Epoch 19/600\n",
      "500/500 [==============================] - 2s - loss: 0.2061 - val_loss: 0.2778\n",
      "Epoch 20/600\n",
      "500/500 [==============================] - 1s - loss: 0.2041 - val_loss: 0.2765\n",
      "Epoch 21/600\n",
      "500/500 [==============================] - 2s - loss: 0.2044 - val_loss: 0.2771\n",
      "Epoch 22/600\n",
      "500/500 [==============================] - 2s - loss: 0.2048 - val_loss: 0.2767\n",
      "Epoch 23/600\n",
      "500/500 [==============================] - 2s - loss: 0.2039 - val_loss: 0.2762\n",
      "Epoch 24/600\n",
      "500/500 [==============================] - 2s - loss: 0.2042 - val_loss: 0.2758\n",
      "Epoch 25/600\n",
      "500/500 [==============================] - 2s - loss: 0.2033 - val_loss: 0.2760\n",
      "Epoch 26/600\n",
      "500/500 [==============================] - 1s - loss: 0.2035 - val_loss: 0.2747\n",
      "Epoch 27/600\n",
      "500/500 [==============================] - 2s - loss: 0.2032 - val_loss: 0.2758\n",
      "Epoch 28/600\n",
      "500/500 [==============================] - 2s - loss: 0.2036 - val_loss: 0.2751\n",
      "Epoch 29/600\n",
      "500/500 [==============================] - 2s - loss: 0.2031 - val_loss: 0.2749\n",
      "Epoch 30/600\n",
      "500/500 [==============================] - 2s - loss: 0.2032 - val_loss: 0.2750\n",
      "Epoch 31/600\n",
      "500/500 [==============================] - 2s - loss: 0.2025 - val_loss: 0.2741\n",
      "Epoch 32/600\n",
      "500/500 [==============================] - 1s - loss: 0.2024 - val_loss: 0.2746\n",
      "Epoch 33/600\n",
      "500/500 [==============================] - 1s - loss: 0.2026 - val_loss: 0.2742\n",
      "Epoch 34/600\n",
      "500/500 [==============================] - 2s - loss: 0.2028 - val_loss: 0.2748\n",
      "Epoch 35/600\n",
      "500/500 [==============================] - 2s - loss: 0.2030 - val_loss: 0.2745\n",
      "Epoch 36/600\n",
      "500/500 [==============================] - 1s - loss: 0.2023 - val_loss: 0.2738\n",
      "Epoch 37/600\n",
      "500/500 [==============================] - 2s - loss: 0.2018 - val_loss: 0.2748\n",
      "Epoch 38/600\n",
      "500/500 [==============================] - 2s - loss: 0.2026 - val_loss: 0.2749\n",
      "Epoch 39/600\n",
      "500/500 [==============================] - 2s - loss: 0.2014 - val_loss: 0.2732\n",
      "Epoch 40/600\n",
      "500/500 [==============================] - 2s - loss: 0.2017 - val_loss: 0.2751\n",
      "Epoch 41/600\n",
      "500/500 [==============================] - 2s - loss: 0.2024 - val_loss: 0.2745\n",
      "Epoch 42/600\n",
      "500/500 [==============================] - 2s - loss: 0.2018 - val_loss: 0.2741\n",
      "Epoch 43/600\n",
      "500/500 [==============================] - 2s - loss: 0.2012 - val_loss: 0.2743\n",
      "Epoch 44/600\n",
      "500/500 [==============================] - 2s - loss: 0.2021 - val_loss: 0.2738\n",
      "Epoch 45/600\n",
      "500/500 [==============================] - 1s - loss: 0.2014 - val_loss: 0.2729\n",
      "Epoch 46/600\n",
      "500/500 [==============================] - 2s - loss: 0.2011 - val_loss: 0.2756\n",
      "Epoch 47/600\n",
      "500/500 [==============================] - 2s - loss: 0.2019 - val_loss: 0.2741\n",
      "Epoch 48/600\n",
      "500/500 [==============================] - 1s - loss: 0.2012 - val_loss: 0.2731\n",
      "Epoch 49/600\n",
      "500/500 [==============================] - 2s - loss: 0.2010 - val_loss: 0.2744\n",
      "Epoch 50/600\n",
      "500/500 [==============================] - 1s - loss: 0.2015 - val_loss: 0.2732\n",
      "Epoch 51/600\n",
      "500/500 [==============================] - 1s - loss: 0.2009 - val_loss: 0.2736\n",
      "Epoch 52/600\n",
      "500/500 [==============================] - 1s - loss: 0.2010 - val_loss: 0.2735\n",
      "Epoch 53/600\n",
      "500/500 [==============================] - 1s - loss: 0.2006 - val_loss: 0.2732\n",
      "Epoch 54/600\n",
      "500/500 [==============================] - 2s - loss: 0.2008 - val_loss: 0.2732\n",
      "Epoch 55/600\n",
      "500/500 [==============================] - 2s - loss: 0.2010 - val_loss: 0.2744\n",
      "Epoch 56/600\n",
      "500/500 [==============================] - 2s - loss: 0.2017 - val_loss: 0.2732\n",
      "Epoch 57/600\n",
      "500/500 [==============================] - 2s - loss: 0.2009 - val_loss: 0.2729\n",
      "Epoch 58/600\n",
      "500/500 [==============================] - 2s - loss: 0.2005 - val_loss: 0.2732\n",
      "Epoch 59/600\n",
      "500/500 [==============================] - 2s - loss: 0.2009 - val_loss: 0.2734\n",
      "Epoch 60/600\n",
      "500/500 [==============================] - 2s - loss: 0.2011 - val_loss: 0.2739\n",
      "Epoch 61/600\n",
      "500/500 [==============================] - 1s - loss: 0.2008 - val_loss: 0.2731\n",
      "Epoch 62/600\n",
      "500/500 [==============================] - 1s - loss: 0.2000 - val_loss: 0.2720\n",
      "Epoch 63/600\n",
      "500/500 [==============================] - 2s - loss: 0.1997 - val_loss: 0.2725\n",
      "Epoch 64/600\n",
      "500/500 [==============================] - 2s - loss: 0.2008 - val_loss: 0.2736\n",
      "Epoch 65/600\n",
      "500/500 [==============================] - 2s - loss: 0.2005 - val_loss: 0.2729\n",
      "Epoch 66/600\n",
      "500/500 [==============================] - 2s - loss: 0.2005 - val_loss: 0.2722\n",
      "Epoch 67/600\n",
      "500/500 [==============================] - 1s - loss: 0.2001 - val_loss: 0.2721\n",
      "Epoch 68/600\n",
      "500/500 [==============================] - 1s - loss: 0.2001 - val_loss: 0.2728\n",
      "Epoch 69/600\n",
      "500/500 [==============================] - 1s - loss: 0.2003 - val_loss: 0.2726\n",
      "Epoch 70/600\n",
      "500/500 [==============================] - 2s - loss: 0.1998 - val_loss: 0.2723\n",
      "Epoch 71/600\n",
      "500/500 [==============================] - 1s - loss: 0.1998 - val_loss: 0.2720\n",
      "Epoch 72/600\n",
      "500/500 [==============================] - 1s - loss: 0.2003 - val_loss: 0.2732\n",
      "Epoch 73/600\n",
      "500/500 [==============================] - 2s - loss: 0.2000 - val_loss: 0.2726\n",
      "Epoch 74/600\n",
      "500/500 [==============================] - 2s - loss: 0.2000 - val_loss: 0.2722\n",
      "Epoch 75/600\n",
      "500/500 [==============================] - 1s - loss: 0.1999 - val_loss: 0.2724\n",
      "Epoch 76/600\n",
      "500/500 [==============================] - 1s - loss: 0.1997 - val_loss: 0.2722\n",
      "Epoch 77/600\n",
      "500/500 [==============================] - 1s - loss: 0.1997 - val_loss: 0.2718\n",
      "Epoch 78/600\n",
      "500/500 [==============================] - 1s - loss: 0.1997 - val_loss: 0.2715\n",
      "Epoch 79/600\n",
      "500/500 [==============================] - 1s - loss: 0.2000 - val_loss: 0.2731\n",
      "Epoch 80/600\n",
      "500/500 [==============================] - 1s - loss: 0.2003 - val_loss: 0.2720\n",
      "Epoch 81/600\n",
      "500/500 [==============================] - 1s - loss: 0.1994 - val_loss: 0.2710\n",
      "Epoch 82/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2708\n",
      "Epoch 83/600\n",
      "500/500 [==============================] - 1s - loss: 0.1994 - val_loss: 0.2721\n",
      "Epoch 84/600\n",
      "500/500 [==============================] - 1s - loss: 0.1995 - val_loss: 0.2718\n",
      "Epoch 85/600\n",
      "500/500 [==============================] - 1s - loss: 0.1994 - val_loss: 0.2722\n",
      "Epoch 86/600\n",
      "500/500 [==============================] - 1s - loss: 0.1995 - val_loss: 0.2718\n",
      "Epoch 87/600\n",
      "500/500 [==============================] - 1s - loss: 0.1996 - val_loss: 0.2721\n",
      "Epoch 88/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s - loss: 0.1995 - val_loss: 0.2716\n",
      "Epoch 89/600\n",
      "500/500 [==============================] - 1s - loss: 0.1999 - val_loss: 0.2719\n",
      "Epoch 90/600\n",
      "500/500 [==============================] - 1s - loss: 0.1992 - val_loss: 0.2713\n",
      "Epoch 91/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2708\n",
      "Epoch 92/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2715\n",
      "Epoch 93/600\n",
      "500/500 [==============================] - 1s - loss: 0.1994 - val_loss: 0.2710\n",
      "Epoch 94/600\n",
      "500/500 [==============================] - 1s - loss: 0.1991 - val_loss: 0.2719\n",
      "Epoch 95/600\n",
      "500/500 [==============================] - 1s - loss: 0.1993 - val_loss: 0.2716\n",
      "Epoch 96/600\n",
      "500/500 [==============================] - 1s - loss: 0.1992 - val_loss: 0.2718\n",
      "Epoch 97/600\n",
      "500/500 [==============================] - 1s - loss: 0.1992 - val_loss: 0.2718\n",
      "Epoch 98/600\n",
      "500/500 [==============================] - 1s - loss: 0.1993 - val_loss: 0.2711\n",
      "Epoch 99/600\n",
      "500/500 [==============================] - 1s - loss: 0.1983 - val_loss: 0.2702\n",
      "Epoch 100/600\n",
      "500/500 [==============================] - 1s - loss: 0.1982 - val_loss: 0.2701\n",
      "Epoch 101/600\n",
      "500/500 [==============================] - 1s - loss: 0.1990 - val_loss: 0.2704\n",
      "Epoch 102/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2704\n",
      "Epoch 103/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2705\n",
      "Epoch 104/600\n",
      "500/500 [==============================] - 1s - loss: 0.1989 - val_loss: 0.2702\n",
      "Epoch 105/600\n",
      "500/500 [==============================] - 1s - loss: 0.1986 - val_loss: 0.2703\n",
      "Epoch 106/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2703\n",
      "Epoch 107/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2701\n",
      "Epoch 108/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2703\n",
      "Epoch 109/600\n",
      "500/500 [==============================] - 1s - loss: 0.1989 - val_loss: 0.2706\n",
      "Epoch 110/600\n",
      "500/500 [==============================] - 1s - loss: 0.1990 - val_loss: 0.2702\n",
      "Epoch 111/600\n",
      "500/500 [==============================] - 1s - loss: 0.1984 - val_loss: 0.2701\n",
      "Epoch 112/600\n",
      "500/500 [==============================] - 1s - loss: 0.1985 - val_loss: 0.2700\n",
      "Epoch 113/600\n",
      "500/500 [==============================] - 1s - loss: 0.1988 - val_loss: 0.2706\n",
      "Epoch 114/600\n",
      "500/500 [==============================] - 1s - loss: 0.1990 - val_loss: 0.2705\n",
      "Epoch 115/600\n",
      "500/500 [==============================] - 1s - loss: 0.1989 - val_loss: 0.2703\n",
      "Epoch 116/600\n",
      "500/500 [==============================] - 1s - loss: 0.1984 - val_loss: 0.2700\n",
      "Epoch 117/600\n",
      "500/500 [==============================] - 1s - loss: 0.1984 - val_loss: 0.2700\n",
      "Epoch 118/600\n",
      "500/500 [==============================] - 1s - loss: 0.1987 - val_loss: 0.2702\n",
      "Epoch 119/600\n",
      "500/500 [==============================] - 1s - loss: 0.1984 - val_loss: 0.2698\n",
      "Epoch 120/600\n",
      "500/500 [==============================] - 1s - loss: 0.1986 - val_loss: 0.2701\n",
      "Epoch 121/600\n",
      "500/500 [==============================] - 1s - loss: 0.1983 - val_loss: 0.2701\n",
      "Epoch 122/600\n",
      "500/500 [==============================] - 1s - loss: 0.1986 - val_loss: 0.2699\n",
      "Epoch 123/600\n",
      "500/500 [==============================] - 1s - loss: 0.1987 - val_loss: 0.2701\n",
      "Epoch 124/600\n",
      "500/500 [==============================] - 1s - loss: 0.1986 - val_loss: 0.2698\n",
      "Epoch 125/600\n",
      "500/500 [==============================] - 1s - loss: 0.1983 - val_loss: 0.2700\n",
      "Epoch 126/600\n",
      "500/500 [==============================] - 1s - loss: 0.1986 - val_loss: 0.2698\n",
      "Epoch 127/600\n",
      "500/500 [==============================] - 1s - loss: 0.1979 - val_loss: 0.2696\n",
      "Epoch 128/600\n",
      "500/500 [==============================] - 1s - loss: 0.1982 - val_loss: 0.2700\n",
      "Epoch 129/600\n",
      "500/500 [==============================] - 1s - loss: 0.1984 - val_loss: 0.2697\n",
      "Epoch 130/600\n",
      "500/500 [==============================] - 1s - loss: 0.1980 - val_loss: 0.2695\n",
      "Epoch 131/600\n",
      "500/500 [==============================] - 1s - loss: 0.1984 - val_loss: 0.2702\n",
      "Epoch 132/600\n",
      "500/500 [==============================] - 1s - loss: 0.1985 - val_loss: 0.2698\n",
      "Epoch 133/600\n",
      "500/500 [==============================] - 1s - loss: 0.1983 - val_loss: 0.2696\n",
      "Epoch 134/600\n",
      "500/500 [==============================] - 1s - loss: 0.1983 - val_loss: 0.2696\n",
      "Epoch 135/600\n",
      "500/500 [==============================] - 1s - loss: 0.1980 - val_loss: 0.2702\n",
      "Epoch 136/600\n",
      "500/500 [==============================] - 1s - loss: 0.1986 - val_loss: 0.2697\n",
      "Epoch 137/600\n",
      "500/500 [==============================] - 1s - loss: 0.1981 - val_loss: 0.2696\n",
      "Epoch 138/600\n",
      "500/500 [==============================] - 1s - loss: 0.1984 - val_loss: 0.2697\n",
      "Epoch 139/600\n",
      "500/500 [==============================] - 1s - loss: 0.1981 - val_loss: 0.2698ss: 0.\n",
      "Epoch 140/600\n",
      "500/500 [==============================] - 1s - loss: 0.1981 - val_loss: 0.2695\n",
      "Epoch 141/600\n",
      "500/500 [==============================] - 1s - loss: 0.1981 - val_loss: 0.2699\n",
      "Epoch 142/600\n",
      "500/500 [==============================] - 1s - loss: 0.1983 - val_loss: 0.2693\n",
      "Epoch 143/600\n",
      "500/500 [==============================] - 1s - loss: 0.1974 - val_loss: 0.2692\n",
      "Epoch 144/600\n",
      "500/500 [==============================] - 1s - loss: 0.1976 - val_loss: 0.2696\n",
      "Epoch 145/600\n",
      "500/500 [==============================] - 1s - loss: 0.1982 - val_loss: 0.2695ss: 0.19\n",
      "Epoch 146/600\n",
      "500/500 [==============================] - 1s - loss: 0.1979 - val_loss: 0.2692\n",
      "Epoch 147/600\n",
      "500/500 [==============================] - 1s - loss: 0.1977 - val_loss: 0.2695\n",
      "Epoch 148/600\n",
      "500/500 [==============================] - 1s - loss: 0.1981 - val_loss: 0.2696\n",
      "Epoch 149/600\n",
      "500/500 [==============================] - 1s - loss: 0.1980 - val_loss: 0.2695\n",
      "Epoch 150/600\n",
      "500/500 [==============================] - 1s - loss: 0.1977 - val_loss: 0.2694\n",
      "Epoch 151/600\n",
      "500/500 [==============================] - 1s - loss: 0.1977 - val_loss: 0.2693\n",
      "Epoch 152/600\n",
      "500/500 [==============================] - 1s - loss: 0.1982 - val_loss: 0.2694\n",
      "Epoch 153/600\n",
      "500/500 [==============================] - 1s - loss: 0.1982 - val_loss: 0.2692\n",
      "Epoch 154/600\n",
      "500/500 [==============================] - 1s - loss: 0.1977 - val_loss: 0.2693\n",
      "Epoch 155/600\n",
      "500/500 [==============================] - 1s - loss: 0.1977 - val_loss: 0.2694\n",
      "Epoch 156/600\n",
      "500/500 [==============================] - 1s - loss: 0.1978 - val_loss: 0.2692\n",
      "Epoch 157/600\n",
      "500/500 [==============================] - 1s - loss: 0.1983 - val_loss: 0.2691\n",
      "Epoch 158/600\n",
      "500/500 [==============================] - 1s - loss: 0.1973 - val_loss: 0.2694\n",
      "Epoch 159/600\n",
      "500/500 [==============================] - 1s - loss: 0.1978 - val_loss: 0.2689\n",
      "Epoch 160/600\n",
      "500/500 [==============================] - 1s - loss: 0.1975 - val_loss: 0.2691\n",
      "Epoch 161/600\n",
      "500/500 [==============================] - 1s - loss: 0.1974 - val_loss: 0.2691\n",
      "Epoch 162/600\n",
      "500/500 [==============================] - 1s - loss: 0.1980 - val_loss: 0.2695\n",
      "Epoch 163/600\n",
      "500/500 [==============================] - 1s - loss: 0.1978 - val_loss: 0.2698\n",
      "Epoch 164/600\n",
      "500/500 [==============================] - 1s - loss: 0.1978 - val_loss: 0.2691\n",
      "Epoch 165/600\n",
      "500/500 [==============================] - 1s - loss: 0.1974 - val_loss: 0.2694ss: 0.\n",
      "Epoch 166/600\n",
      "500/500 [==============================] - 1s - loss: 0.1975 - val_loss: 0.2689\n",
      "Epoch 167/600\n",
      "500/500 [==============================] - 1s - loss: 0.1973 - val_loss: 0.2689\n",
      "Epoch 168/600\n",
      "500/500 [==============================] - 1s - loss: 0.1975 - val_loss: 0.2692\n",
      "Epoch 169/600\n",
      "500/500 [==============================] - 1s - loss: 0.1977 - val_loss: 0.2688\n",
      "Epoch 170/600\n",
      "500/500 [==============================] - 1s - loss: 0.1972 - val_loss: 0.2690\n",
      "Epoch 171/600\n",
      "500/500 [==============================] - 1s - loss: 0.1979 - val_loss: 0.2689\n",
      "Epoch 172/600\n",
      "500/500 [==============================] - 1s - loss: 0.1975 - val_loss: 0.2688\n",
      "Epoch 173/600\n",
      "500/500 [==============================] - 1s - loss: 0.1974 - val_loss: 0.2693\n",
      "Epoch 174/600\n",
      "500/500 [==============================] - 1s - loss: 0.1978 - val_loss: 0.2688\n",
      "Epoch 175/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s - loss: 0.1971 - val_loss: 0.2687\n",
      "Epoch 176/600\n",
      "500/500 [==============================] - 1s - loss: 0.1973 - val_loss: 0.2692\n",
      "Epoch 177/600\n",
      "500/500 [==============================] - 2s - loss: 0.1973 - val_loss: 0.2687\n",
      "Epoch 178/600\n",
      "500/500 [==============================] - 2s - loss: 0.1971 - val_loss: 0.2688\n",
      "Epoch 179/600\n",
      "500/500 [==============================] - 2s - loss: 0.1973 - val_loss: 0.2688\n",
      "Epoch 180/600\n",
      "500/500 [==============================] - 2s - loss: 0.1976 - val_loss: 0.2687\n",
      "Epoch 181/600\n",
      "500/500 [==============================] - 2s - loss: 0.1970 - val_loss: 0.2687\n",
      "Epoch 182/600\n",
      "500/500 [==============================] - 2s - loss: 0.1970 - val_loss: 0.2689\n",
      "Epoch 183/600\n",
      "500/500 [==============================] - 2s - loss: 0.1973 - val_loss: 0.2689\n",
      "Epoch 184/600\n",
      "500/500 [==============================] - 2s - loss: 0.1974 - val_loss: 0.2687\n",
      "Epoch 185/600\n",
      "500/500 [==============================] - 2s - loss: 0.1970 - val_loss: 0.2689\n",
      "Epoch 186/600\n",
      "500/500 [==============================] - 2s - loss: 0.1972 - val_loss: 0.2689\n",
      "Epoch 187/600\n",
      "500/500 [==============================] - 2s - loss: 0.1972 - val_loss: 0.2687\n",
      "Epoch 188/600\n",
      "500/500 [==============================] - 2s - loss: 0.1971 - val_loss: 0.2687\n",
      "Epoch 189/600\n",
      "500/500 [==============================] - 3s - loss: 0.1969 - val_loss: 0.2686\n",
      "Epoch 190/600\n",
      "500/500 [==============================] - 3s - loss: 0.1974 - val_loss: 0.2691\n",
      "Epoch 191/600\n",
      "500/500 [==============================] - 2s - loss: 0.1972 - val_loss: 0.2685\n",
      "Epoch 192/600\n",
      "500/500 [==============================] - 2s - loss: 0.1971 - val_loss: 0.2687\n",
      "Epoch 193/600\n",
      "500/500 [==============================] - 2s - loss: 0.1971 - val_loss: 0.2687\n",
      "Epoch 194/600\n",
      "500/500 [==============================] - 2s - loss: 0.1969 - val_loss: 0.2686\n",
      "Epoch 195/600\n",
      "500/500 [==============================] - 1s - loss: 0.1969 - val_loss: 0.2687\n",
      "Epoch 196/600\n",
      "500/500 [==============================] - 1s - loss: 0.1973 - val_loss: 0.2687\n",
      "Epoch 197/600\n",
      "500/500 [==============================] - 1s - loss: 0.1968 - val_loss: 0.2684\n",
      "Epoch 198/600\n",
      "500/500 [==============================] - 1s - loss: 0.1970 - val_loss: 0.2688\n",
      "Epoch 199/600\n",
      "500/500 [==============================] - 2s - loss: 0.1971 - val_loss: 0.2688\n",
      "Epoch 200/600\n",
      "500/500 [==============================] - 1s - loss: 0.1972 - val_loss: 0.2686\n",
      "Epoch 201/600\n",
      "500/500 [==============================] - 1s - loss: 0.1970 - val_loss: 0.2683\n",
      "Epoch 202/600\n",
      "500/500 [==============================] - 1s - loss: 0.1970 - val_loss: 0.2687\n",
      "Epoch 203/600\n",
      "500/500 [==============================] - 1s - loss: 0.1972 - val_loss: 0.2684\n",
      "Epoch 204/600\n",
      "500/500 [==============================] - 1s - loss: 0.1969 - val_loss: 0.2684\n",
      "Epoch 205/600\n",
      "500/500 [==============================] - 1s - loss: 0.1967 - val_loss: 0.2684\n",
      "Epoch 206/600\n",
      "500/500 [==============================] - 1s - loss: 0.1969 - val_loss: 0.2685\n",
      "Epoch 207/600\n",
      "500/500 [==============================] - 2s - loss: 0.1971 - val_loss: 0.2685\n",
      "Epoch 208/600\n",
      "500/500 [==============================] - 1s - loss: 0.1970 - val_loss: 0.2685\n",
      "Epoch 209/600\n",
      "500/500 [==============================] - 2s - loss: 0.1971 - val_loss: 0.2689\n",
      "Epoch 210/600\n",
      "500/500 [==============================] - 1s - loss: 0.1969 - val_loss: 0.2682\n",
      "Epoch 211/600\n",
      "500/500 [==============================] - 1s - loss: 0.1966 - val_loss: 0.2682\n",
      "Epoch 212/600\n",
      "500/500 [==============================] - 1s - loss: 0.1968 - val_loss: 0.2685\n",
      "Epoch 213/600\n",
      "500/500 [==============================] - 1s - loss: 0.1966 - val_loss: 0.2684\n",
      "Epoch 214/600\n",
      "500/500 [==============================] - 1s - loss: 0.1967 - val_loss: 0.2683\n",
      "Epoch 215/600\n",
      "500/500 [==============================] - 1s - loss: 0.1969 - val_loss: 0.2683\n",
      "Epoch 216/600\n",
      "500/500 [==============================] - 1s - loss: 0.1967 - val_loss: 0.2681\n",
      "Epoch 217/600\n",
      "500/500 [==============================] - 1s - loss: 0.1965 - val_loss: 0.2684\n",
      "Epoch 218/600\n",
      "500/500 [==============================] - 1s - loss: 0.1971 - val_loss: 0.2684\n",
      "Epoch 219/600\n",
      "500/500 [==============================] - 1s - loss: 0.1968 - val_loss: 0.2681\n",
      "Epoch 220/600\n",
      "500/500 [==============================] - 3s - loss: 0.1962 - val_loss: 0.2680\n",
      "Epoch 221/600\n",
      "500/500 [==============================] - 2s - loss: 0.1963 - val_loss: 0.2683\n",
      "Epoch 222/600\n",
      "500/500 [==============================] - 3s - loss: 0.1966 - val_loss: 0.2680\n",
      "Epoch 223/600\n",
      "500/500 [==============================] - 2s - loss: 0.1965 - val_loss: 0.2681\n",
      "Epoch 224/600\n",
      "500/500 [==============================] - 1s - loss: 0.1965 - val_loss: 0.2680\n",
      "Epoch 225/600\n",
      "500/500 [==============================] - 2s - loss: 0.1966 - val_loss: 0.2682\n",
      "Epoch 226/600\n",
      "500/500 [==============================] - 2s - loss: 0.1968 - val_loss: 0.2680\n",
      "Epoch 227/600\n",
      "500/500 [==============================] - 2s - loss: 0.1963 - val_loss: 0.2681\n",
      "Epoch 228/600\n",
      "500/500 [==============================] - 1s - loss: 0.1966 - val_loss: 0.2680\n",
      "Epoch 229/600\n",
      "500/500 [==============================] - 1s - loss: 0.1961 - val_loss: 0.2679\n",
      "Epoch 230/600\n",
      "500/500 [==============================] - 1s - loss: 0.1965 - val_loss: 0.2681\n",
      "Epoch 231/600\n",
      "500/500 [==============================] - 1s - loss: 0.1965 - val_loss: 0.2681\n",
      "Epoch 232/600\n",
      "500/500 [==============================] - 2s - loss: 0.1965 - val_loss: 0.2679\n",
      "Epoch 233/600\n",
      "500/500 [==============================] - 2s - loss: 0.1965 - val_loss: 0.2684\n",
      "Epoch 234/600\n",
      "500/500 [==============================] - 1s - loss: 0.1967 - val_loss: 0.2680\n",
      "Epoch 235/600\n",
      "500/500 [==============================] - 1s - loss: 0.1963 - val_loss: 0.2681\n",
      "Epoch 236/600\n",
      "500/500 [==============================] - 1s - loss: 0.1964 - val_loss: 0.2680\n",
      "Epoch 237/600\n",
      "500/500 [==============================] - 2s - loss: 0.1964 - val_loss: 0.2681\n",
      "Epoch 238/600\n",
      "500/500 [==============================] - 2s - loss: 0.1964 - val_loss: 0.2681\n",
      "Epoch 239/600\n",
      "500/500 [==============================] - 1s - loss: 0.1968 - val_loss: 0.2681\n",
      "Epoch 240/600\n",
      "500/500 [==============================] - 2s - loss: 0.1967 - val_loss: 0.2680\n",
      "Epoch 241/600\n",
      "500/500 [==============================] - 2s - loss: 0.1963 - val_loss: 0.2677\n",
      "Epoch 242/600\n",
      "500/500 [==============================] - 1s - loss: 0.1963 - val_loss: 0.2680\n",
      "Epoch 243/600\n",
      "500/500 [==============================] - 1s - loss: 0.1965 - val_loss: 0.2679\n",
      "Epoch 244/600\n",
      "500/500 [==============================] - 1s - loss: 0.1965 - val_loss: 0.2681\n",
      "Epoch 245/600\n",
      "500/500 [==============================] - 1s - loss: 0.1963 - val_loss: 0.2682\n",
      "Epoch 246/600\n",
      "500/500 [==============================] - 1s - loss: 0.1965 - val_loss: 0.2678\n",
      "Epoch 247/600\n",
      "500/500 [==============================] - 1s - loss: 0.1960 - val_loss: 0.2679\n",
      "Epoch 248/600\n",
      "500/500 [==============================] - 2s - loss: 0.1963 - val_loss: 0.2681\n",
      "Epoch 249/600\n",
      "500/500 [==============================] - 2s - loss: 0.1964 - val_loss: 0.2676\n",
      "Epoch 250/600\n",
      "500/500 [==============================] - 2s - loss: 0.1958 - val_loss: 0.2676\n",
      "Epoch 251/600\n",
      "500/500 [==============================] - 2s - loss: 0.1963 - val_loss: 0.2680\n",
      "Epoch 252/600\n",
      "500/500 [==============================] - 2s - loss: 0.1962 - val_loss: 0.2679\n",
      "Epoch 253/600\n",
      "500/500 [==============================] - 1s - loss: 0.1962 - val_loss: 0.2677\n",
      "Epoch 254/600\n",
      "500/500 [==============================] - 1s - loss: 0.1960 - val_loss: 0.2676\n",
      "Epoch 255/600\n",
      "500/500 [==============================] - 2s - loss: 0.1961 - val_loss: 0.2678\n",
      "Epoch 256/600\n",
      "500/500 [==============================] - 2s - loss: 0.1964 - val_loss: 0.2679\n",
      "Epoch 257/600\n",
      "500/500 [==============================] - 2s - loss: 0.1961 - val_loss: 0.2677\n",
      "Epoch 258/600\n",
      "500/500 [==============================] - 2s - loss: 0.1959 - val_loss: 0.2676\n",
      "Epoch 259/600\n",
      "500/500 [==============================] - 1s - loss: 0.1962 - val_loss: 0.2677\n",
      "Epoch 260/600\n",
      "500/500 [==============================] - 2s - loss: 0.1961 - val_loss: 0.2678\n",
      "Epoch 261/600\n",
      "500/500 [==============================] - 2s - loss: 0.1964 - val_loss: 0.2678\n",
      "Epoch 262/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s - loss: 0.1960 - val_loss: 0.2675\n",
      "Epoch 263/600\n",
      "500/500 [==============================] - 2s - loss: 0.1962 - val_loss: 0.2677\n",
      "Epoch 264/600\n",
      "500/500 [==============================] - 1s - loss: 0.1962 - val_loss: 0.2680\n",
      "Epoch 265/600\n",
      "500/500 [==============================] - 2s - loss: 0.1963 - val_loss: 0.2675\n",
      "Epoch 266/600\n",
      "500/500 [==============================] - 2s - loss: 0.1958 - val_loss: 0.2677\n",
      "Epoch 267/600\n",
      "500/500 [==============================] - 1s - loss: 0.1961 - val_loss: 0.2678\n",
      "Epoch 268/600\n",
      "500/500 [==============================] - 1s - loss: 0.1961 - val_loss: 0.2676\n",
      "Epoch 269/600\n",
      "500/500 [==============================] - 2s - loss: 0.1960 - val_loss: 0.2677\n",
      "Epoch 270/600\n",
      "500/500 [==============================] - 2s - loss: 0.1958 - val_loss: 0.2676\n",
      "Epoch 271/600\n",
      "500/500 [==============================] - 2s - loss: 0.1959 - val_loss: 0.2676\n",
      "Epoch 272/600\n",
      "500/500 [==============================] - 2s - loss: 0.1962 - val_loss: 0.2680\n",
      "Epoch 273/600\n",
      "500/500 [==============================] - 2s - loss: 0.1965 - val_loss: 0.2676\n",
      "Epoch 274/600\n",
      "500/500 [==============================] - 2s - loss: 0.1958 - val_loss: 0.2676\n",
      "Epoch 275/600\n",
      "500/500 [==============================] - 2s - loss: 0.1962 - val_loss: 0.2676\n",
      "Epoch 276/600\n",
      "500/500 [==============================] - 2s - loss: 0.1959 - val_loss: 0.2674\n",
      "Epoch 277/600\n",
      "500/500 [==============================] - 2s - loss: 0.1957 - val_loss: 0.2676\n",
      "Epoch 278/600\n",
      "500/500 [==============================] - 2s - loss: 0.1957 - val_loss: 0.2674\n",
      "Epoch 279/600\n",
      "500/500 [==============================] - 2s - loss: 0.1958 - val_loss: 0.2678\n",
      "Epoch 280/600\n",
      "500/500 [==============================] - 2s - loss: 0.1964 - val_loss: 0.2676\n",
      "Epoch 281/600\n",
      "500/500 [==============================] - 2s - loss: 0.1959 - val_loss: 0.2676\n",
      "Epoch 282/600\n",
      "500/500 [==============================] - 2s - loss: 0.1959 - val_loss: 0.2674\n",
      "Epoch 283/600\n",
      "500/500 [==============================] - 2s - loss: 0.1957 - val_loss: 0.2674\n",
      "Epoch 284/600\n",
      "500/500 [==============================] - 1s - loss: 0.1958 - val_loss: 0.2674\n",
      "Epoch 285/600\n",
      "500/500 [==============================] - 1s - loss: 0.1958 - val_loss: 0.2676\n",
      "Epoch 286/600\n",
      "500/500 [==============================] - 1s - loss: 0.1961 - val_loss: 0.2676\n",
      "Epoch 287/600\n",
      "500/500 [==============================] - 1s - loss: 0.1956 - val_loss: 0.2673\n",
      "Epoch 288/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2675\n",
      "Epoch 289/600\n",
      "500/500 [==============================] - 2s - loss: 0.1962 - val_loss: 0.2674\n",
      "Epoch 290/600\n",
      "500/500 [==============================] - 1s - loss: 0.1958 - val_loss: 0.2675\n",
      "Epoch 291/600\n",
      "500/500 [==============================] - 2s - loss: 0.1960 - val_loss: 0.2674\n",
      "Epoch 292/600\n",
      "500/500 [==============================] - 1s - loss: 0.1959 - val_loss: 0.2679\n",
      "Epoch 293/600\n",
      "500/500 [==============================] - 1s - loss: 0.1960 - val_loss: 0.2673\n",
      "Epoch 294/600\n",
      "500/500 [==============================] - 1s - loss: 0.1953 - val_loss: 0.2673\n",
      "Epoch 295/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2679\n",
      "Epoch 296/600\n",
      "500/500 [==============================] - 1s - loss: 0.1959 - val_loss: 0.2676\n",
      "Epoch 297/600\n",
      "500/500 [==============================] - 1s - loss: 0.1958 - val_loss: 0.2672\n",
      "Epoch 298/600\n",
      "500/500 [==============================] - 1s - loss: 0.1954 - val_loss: 0.2671\n",
      "Epoch 299/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2674\n",
      "Epoch 300/600\n",
      "500/500 [==============================] - 1s - loss: 0.1958 - val_loss: 0.2673\n",
      "Epoch 301/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2672\n",
      "Epoch 302/600\n",
      "500/500 [==============================] - 1s - loss: 0.1955 - val_loss: 0.2673\n",
      "Epoch 303/600\n",
      "500/500 [==============================] - 1s - loss: 0.1958 - val_loss: 0.2675\n",
      "Epoch 304/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2675\n",
      "Epoch 305/600\n",
      "500/500 [==============================] - 1s - loss: 0.1958 - val_loss: 0.2673\n",
      "Epoch 306/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2671\n",
      "Epoch 307/600\n",
      "500/500 [==============================] - 1s - loss: 0.1953 - val_loss: 0.2672\n",
      "Epoch 308/600\n",
      "500/500 [==============================] - 1s - loss: 0.1955 - val_loss: 0.2674\n",
      "Epoch 309/600\n",
      "500/500 [==============================] - 1s - loss: 0.1959 - val_loss: 0.2674\n",
      "Epoch 310/600\n",
      "500/500 [==============================] - 2s - loss: 0.1956 - val_loss: 0.2673\n",
      "Epoch 311/600\n",
      "500/500 [==============================] - 2s - loss: 0.1956 - val_loss: 0.2674\n",
      "Epoch 312/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2672\n",
      "Epoch 313/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2675\n",
      "Epoch 314/600\n",
      "500/500 [==============================] - 1s - loss: 0.1956 - val_loss: 0.2672\n",
      "Epoch 315/600\n",
      "500/500 [==============================] - 1s - loss: 0.1955 - val_loss: 0.2677\n",
      "Epoch 316/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2674ss: 0.1\n",
      "Epoch 317/600\n",
      "500/500 [==============================] - 1s - loss: 0.1959 - val_loss: 0.2674\n",
      "Epoch 318/600\n",
      "500/500 [==============================] - 2s - loss: 0.1955 - val_loss: 0.2672\n",
      "Epoch 319/600\n",
      "500/500 [==============================] - 1s - loss: 0.1954 - val_loss: 0.2671\n",
      "Epoch 320/600\n",
      "500/500 [==============================] - 1s - loss: 0.1956 - val_loss: 0.2671\n",
      "Epoch 321/600\n",
      "500/500 [==============================] - 1s - loss: 0.1957 - val_loss: 0.2671\n",
      "Epoch 322/600\n",
      "500/500 [==============================] - 2s - loss: 0.1950 - val_loss: 0.2671\n",
      "Epoch 323/600\n",
      "500/500 [==============================] - 1s - loss: 0.1953 - val_loss: 0.2672\n",
      "Epoch 324/600\n",
      "500/500 [==============================] - 2s - loss: 0.1955 - val_loss: 0.2670\n",
      "Epoch 325/600\n",
      "500/500 [==============================] - 2s - loss: 0.1955 - val_loss: 0.2671\n",
      "Epoch 326/600\n",
      "500/500 [==============================] - 2s - loss: 0.1953 - val_loss: 0.2673\n",
      "Epoch 327/600\n",
      "500/500 [==============================] - 2s - loss: 0.1957 - val_loss: 0.2673\n",
      "Epoch 328/600\n",
      "500/500 [==============================] - 2s - loss: 0.1956 - val_loss: 0.2673\n",
      "Epoch 329/600\n",
      "500/500 [==============================] - 2s - loss: 0.1954 - val_loss: 0.2671\n",
      "Epoch 330/600\n",
      "500/500 [==============================] - 2s - loss: 0.1953 - val_loss: 0.2673\n",
      "Epoch 331/600\n",
      "500/500 [==============================] - 2s - loss: 0.1954 - val_loss: 0.2669\n",
      "Epoch 332/600\n",
      "500/500 [==============================] - 2s - loss: 0.1954 - val_loss: 0.2670\n",
      "Epoch 333/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2672\n",
      "Epoch 334/600\n",
      "500/500 [==============================] - 2s - loss: 0.1956 - val_loss: 0.2673\n",
      "Epoch 335/600\n",
      "500/500 [==============================] - 2s - loss: 0.1955 - val_loss: 0.2672\n",
      "Epoch 336/600\n",
      "500/500 [==============================] - 2s - loss: 0.1952 - val_loss: 0.2670\n",
      "Epoch 337/600\n",
      "500/500 [==============================] - 2s - loss: 0.1955 - val_loss: 0.2671\n",
      "Epoch 338/600\n",
      "500/500 [==============================] - 2s - loss: 0.1954 - val_loss: 0.2671\n",
      "Epoch 339/600\n",
      "500/500 [==============================] - 2s - loss: 0.1954 - val_loss: 0.2671\n",
      "Epoch 340/600\n",
      "500/500 [==============================] - 2s - loss: 0.1953 - val_loss: 0.2671\n",
      "Epoch 341/600\n",
      "500/500 [==============================] - 2s - loss: 0.1953 - val_loss: 0.2672\n",
      "Epoch 342/600\n",
      "500/500 [==============================] - 2s - loss: 0.1954 - val_loss: 0.2670\n",
      "Epoch 343/600\n",
      "500/500 [==============================] - 2s - loss: 0.1953 - val_loss: 0.2670\n",
      "Epoch 344/600\n",
      "500/500 [==============================] - 2s - loss: 0.1952 - val_loss: 0.2669\n",
      "Epoch 345/600\n",
      "500/500 [==============================] - 2s - loss: 0.1956 - val_loss: 0.2670\n",
      "Epoch 346/600\n",
      "500/500 [==============================] - 2s - loss: 0.1953 - val_loss: 0.2669\n",
      "Epoch 347/600\n",
      "500/500 [==============================] - 2s - loss: 0.1954 - val_loss: 0.2670\n",
      "Epoch 348/600\n",
      "500/500 [==============================] - 2s - loss: 0.1955 - val_loss: 0.2671\n",
      "Epoch 349/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s - loss: 0.1956 - val_loss: 0.2672\n",
      "Epoch 350/600\n",
      "500/500 [==============================] - 2s - loss: 0.1953 - val_loss: 0.2672\n",
      "Epoch 351/600\n",
      "500/500 [==============================] - 2s - loss: 0.1954 - val_loss: 0.2674\n",
      "Epoch 352/600\n",
      "500/500 [==============================] - 3s - loss: 0.1954 - val_loss: 0.2669\n",
      "Epoch 353/600\n",
      "500/500 [==============================] - 3s - loss: 0.1952 - val_loss: 0.2671\n",
      "Epoch 354/600\n",
      "500/500 [==============================] - 1s - loss: 0.1954 - val_loss: 0.2669\n",
      "Epoch 355/600\n",
      "500/500 [==============================] - 1s - loss: 0.1954 - val_loss: 0.2670\n",
      "Epoch 356/600\n",
      "500/500 [==============================] - 2s - loss: 0.1953 - val_loss: 0.2669\n",
      "Epoch 357/600\n",
      "500/500 [==============================] - 2s - loss: 0.1951 - val_loss: 0.2668\n",
      "Epoch 358/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2671\n",
      "Epoch 359/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2669\n",
      "Epoch 360/600\n",
      "500/500 [==============================] - 1s - loss: 0.1951 - val_loss: 0.2671\n",
      "Epoch 361/600\n",
      "500/500 [==============================] - 1s - loss: 0.1954 - val_loss: 0.2668\n",
      "Epoch 362/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2669\n",
      "Epoch 363/600\n",
      "500/500 [==============================] - 1s - loss: 0.1951 - val_loss: 0.2670\n",
      "Epoch 364/600\n",
      "500/500 [==============================] - 1s - loss: 0.1953 - val_loss: 0.2667s\n",
      "Epoch 365/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2670\n",
      "Epoch 366/600\n",
      "500/500 [==============================] - 1s - loss: 0.1955 - val_loss: 0.2671ss: 0.\n",
      "Epoch 367/600\n",
      "500/500 [==============================] - 1s - loss: 0.1954 - val_loss: 0.2670\n",
      "Epoch 368/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2669\n",
      "Epoch 369/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2669\n",
      "Epoch 370/600\n",
      "500/500 [==============================] - 2s - loss: 0.1955 - val_loss: 0.2670\n",
      "Epoch 371/600\n",
      "500/500 [==============================] - 2s - loss: 0.1951 - val_loss: 0.2669\n",
      "Epoch 372/600\n",
      "500/500 [==============================] - 1s - loss: 0.1951 - val_loss: 0.2667\n",
      "Epoch 373/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2670\n",
      "Epoch 374/600\n",
      "500/500 [==============================] - 1s - loss: 0.1953 - val_loss: 0.2667\n",
      "Epoch 375/600\n",
      "500/500 [==============================] - 2s - loss: 0.1950 - val_loss: 0.2667\n",
      "Epoch 376/600\n",
      "500/500 [==============================] - 2s - loss: 0.1952 - val_loss: 0.2669\n",
      "Epoch 377/600\n",
      "500/500 [==============================] - 2s - loss: 0.1952 - val_loss: 0.2668\n",
      "Epoch 378/600\n",
      "500/500 [==============================] - 2s - loss: 0.1951 - val_loss: 0.2668\n",
      "Epoch 379/600\n",
      "500/500 [==============================] - 1s - loss: 0.1949 - val_loss: 0.2667\n",
      "Epoch 380/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2669\n",
      "Epoch 381/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2670\n",
      "Epoch 382/600\n",
      "500/500 [==============================] - 1s - loss: 0.1953 - val_loss: 0.2668\n",
      "Epoch 383/600\n",
      "500/500 [==============================] - 1s - loss: 0.1951 - val_loss: 0.2670\n",
      "Epoch 384/600\n",
      "500/500 [==============================] - 1s - loss: 0.1949 - val_loss: 0.2668\n",
      "Epoch 385/600\n",
      "500/500 [==============================] - 1s - loss: 0.1948 - val_loss: 0.2666\n",
      "Epoch 386/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2668\n",
      "Epoch 387/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2668\n",
      "Epoch 388/600\n",
      "500/500 [==============================] - 2s - loss: 0.1951 - val_loss: 0.2669\n",
      "Epoch 389/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2668\n",
      "Epoch 390/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2668\n",
      "Epoch 391/600\n",
      "500/500 [==============================] - 1s - loss: 0.1947 - val_loss: 0.2667\n",
      "Epoch 392/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2674\n",
      "Epoch 393/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2666\n",
      "Epoch 394/600\n",
      "500/500 [==============================] - 1s - loss: 0.1946 - val_loss: 0.2665\n",
      "Epoch 395/600\n",
      "500/500 [==============================] - 1s - loss: 0.1947 - val_loss: 0.2666\n",
      "Epoch 396/600\n",
      "500/500 [==============================] - 1s - loss: 0.1951 - val_loss: 0.2668\n",
      "Epoch 397/600\n",
      "500/500 [==============================] - 1s - loss: 0.1949 - val_loss: 0.2667\n",
      "Epoch 398/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2668\n",
      "Epoch 399/600\n",
      "500/500 [==============================] - 1s - loss: 0.1949 - val_loss: 0.2667\n",
      "Epoch 400/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2668\n",
      "Epoch 401/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2666\n",
      "Epoch 402/600\n",
      "500/500 [==============================] - 1s - loss: 0.1946 - val_loss: 0.2666\n",
      "Epoch 403/600\n",
      "500/500 [==============================] - 2s - loss: 0.1948 - val_loss: 0.2666\n",
      "Epoch 404/600\n",
      "500/500 [==============================] - 1s - loss: 0.1948 - val_loss: 0.2666\n",
      "Epoch 405/600\n",
      "500/500 [==============================] - 1s - loss: 0.1949 - val_loss: 0.2667\n",
      "Epoch 406/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2668\n",
      "Epoch 407/600\n",
      "500/500 [==============================] - 1s - loss: 0.1950 - val_loss: 0.2668s\n",
      "Epoch 408/600\n",
      "500/500 [==============================] - 1s - loss: 0.1949 - val_loss: 0.2666\n",
      "Epoch 409/600\n",
      "500/500 [==============================] - 1s - loss: 0.1948 - val_loss: 0.2666\n",
      "Epoch 410/600\n",
      "500/500 [==============================] - 1s - loss: 0.1949 - val_loss: 0.2665\n",
      "Epoch 411/600\n",
      "500/500 [==============================] - 1s - loss: 0.1948 - val_loss: 0.2669\n",
      "Epoch 412/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2667\n",
      "Epoch 413/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2666\n",
      "Epoch 414/600\n",
      "500/500 [==============================] - 2s - loss: 0.1946 - val_loss: 0.2666\n",
      "Epoch 415/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2667\n",
      "Epoch 416/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2667\n",
      "Epoch 417/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2665\n",
      "Epoch 418/600\n",
      "500/500 [==============================] - 2s - loss: 0.1947 - val_loss: 0.2667\n",
      "Epoch 419/600\n",
      "500/500 [==============================] - 2s - loss: 0.1951 - val_loss: 0.2665\n",
      "Epoch 420/600\n",
      "500/500 [==============================] - 1s - loss: 0.1948 - val_loss: 0.2667\n",
      "Epoch 421/600\n",
      "500/500 [==============================] - 1s - loss: 0.1948 - val_loss: 0.2666\n",
      "Epoch 422/600\n",
      "500/500 [==============================] - 1s - loss: 0.1948 - val_loss: 0.2665\n",
      "Epoch 423/600\n",
      "500/500 [==============================] - 2s - loss: 0.1948 - val_loss: 0.2667\n",
      "Epoch 424/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2666\n",
      "Epoch 425/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2665\n",
      "Epoch 426/600\n",
      "500/500 [==============================] - 2s - loss: 0.1947 - val_loss: 0.2664\n",
      "Epoch 427/600\n",
      "500/500 [==============================] - 2s - loss: 0.1948 - val_loss: 0.2667\n",
      "Epoch 428/600\n",
      "500/500 [==============================] - 2s - loss: 0.1951 - val_loss: 0.2665\n",
      "Epoch 429/600\n",
      "500/500 [==============================] - 2s - loss: 0.1947 - val_loss: 0.2665\n",
      "Epoch 430/600\n",
      "500/500 [==============================] - 2s - loss: 0.1948 - val_loss: 0.2667\n",
      "Epoch 431/600\n",
      "500/500 [==============================] - 1s - loss: 0.1952 - val_loss: 0.2666\n",
      "Epoch 432/600\n",
      "500/500 [==============================] - 2s - loss: 0.1946 - val_loss: 0.2665\n",
      "Epoch 433/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2665\n",
      "Epoch 434/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2665\n",
      "Epoch 435/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2664\n",
      "Epoch 436/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s - loss: 0.1948 - val_loss: 0.2666\n",
      "Epoch 437/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2665\n",
      "Epoch 438/600\n",
      "500/500 [==============================] - 2s - loss: 0.1946 - val_loss: 0.2664\n",
      "Epoch 439/600\n",
      "500/500 [==============================] - 1s - loss: 0.1946 - val_loss: 0.2666\n",
      "Epoch 440/600\n",
      "500/500 [==============================] - 1s - loss: 0.1949 - val_loss: 0.2666\n",
      "Epoch 441/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2663\n",
      "Epoch 442/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2664\n",
      "Epoch 443/600\n",
      "500/500 [==============================] - 2s - loss: 0.1947 - val_loss: 0.2664\n",
      "Epoch 444/600\n",
      "500/500 [==============================] - 2s - loss: 0.1947 - val_loss: 0.2664\n",
      "Epoch 445/600\n",
      "500/500 [==============================] - 1s - loss: 0.1947 - val_loss: 0.2667\n",
      "Epoch 446/600\n",
      "500/500 [==============================] - 1s - loss: 0.1947 - val_loss: 0.2663\n",
      "Epoch 447/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2664\n",
      "Epoch 448/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2665\n",
      "Epoch 449/600\n",
      "500/500 [==============================] - 1s - loss: 0.1947 - val_loss: 0.2665\n",
      "Epoch 450/600\n",
      "500/500 [==============================] - 1s - loss: 0.1946 - val_loss: 0.2666\n",
      "Epoch 451/600\n",
      "500/500 [==============================] - 2s - loss: 0.1950 - val_loss: 0.2665\n",
      "Epoch 452/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2663\n",
      "Epoch 453/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2665\n",
      "Epoch 454/600\n",
      "500/500 [==============================] - 2s - loss: 0.1946 - val_loss: 0.2665\n",
      "Epoch 455/600\n",
      "500/500 [==============================] - 2s - loss: 0.1946 - val_loss: 0.2663\n",
      "Epoch 456/600\n",
      "500/500 [==============================] - 2s - loss: 0.1946 - val_loss: 0.2663\n",
      "Epoch 457/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2663\n",
      "Epoch 458/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2665\n",
      "Epoch 459/600\n",
      "500/500 [==============================] - 2s - loss: 0.1949 - val_loss: 0.2666\n",
      "Epoch 460/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2662\n",
      "Epoch 461/600\n",
      "500/500 [==============================] - 2s - loss: 0.1943 - val_loss: 0.2666\n",
      "Epoch 462/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2664\n",
      "Epoch 463/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2663\n",
      "Epoch 464/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2662\n",
      "Epoch 465/600\n",
      "500/500 [==============================] - 2s - loss: 0.1947 - val_loss: 0.2665\n",
      "Epoch 466/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2664\n",
      "Epoch 467/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2665\n",
      "Epoch 468/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2662\n",
      "Epoch 469/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2663\n",
      "Epoch 470/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2663\n",
      "Epoch 471/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2664\n",
      "Epoch 472/600\n",
      "500/500 [==============================] - 1s - loss: 0.1946 - val_loss: 0.2662\n",
      "Epoch 473/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2664\n",
      "Epoch 474/600\n",
      "500/500 [==============================] - 2s - loss: 0.1943 - val_loss: 0.2662\n",
      "Epoch 475/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2664\n",
      "Epoch 476/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2662\n",
      "Epoch 477/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2663\n",
      "Epoch 478/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2662\n",
      "Epoch 479/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2663\n",
      "Epoch 480/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2663\n",
      "Epoch 481/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2663\n",
      "Epoch 482/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2661\n",
      "Epoch 483/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2664\n",
      "Epoch 484/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2661\n",
      "Epoch 485/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2663\n",
      "Epoch 486/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2664ss: 0.19\n",
      "Epoch 487/600\n",
      "500/500 [==============================] - 1s - loss: 0.1942 - val_loss: 0.2664\n",
      "Epoch 488/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2663\n",
      "Epoch 489/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2663\n",
      "Epoch 490/600\n",
      "500/500 [==============================] - 2s - loss: 0.1945 - val_loss: 0.2662\n",
      "Epoch 491/600\n",
      "500/500 [==============================] - 2s - loss: 0.1942 - val_loss: 0.2661\n",
      "Epoch 492/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2664\n",
      "Epoch 493/600\n",
      "500/500 [==============================] - 1s - loss: 0.1946 - val_loss: 0.2663\n",
      "Epoch 494/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2662\n",
      "Epoch 495/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2661\n",
      "Epoch 496/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2661\n",
      "Epoch 497/600\n",
      "500/500 [==============================] - 1s - loss: 0.1942 - val_loss: 0.2662\n",
      "Epoch 498/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2663\n",
      "Epoch 499/600\n",
      "500/500 [==============================] - 1s - loss: 0.1946 - val_loss: 0.2661\n",
      "Epoch 500/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2662\n",
      "Epoch 501/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2661\n",
      "Epoch 502/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2664\n",
      "Epoch 503/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2661ss\n",
      "Epoch 504/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2662\n",
      "Epoch 505/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2662\n",
      "Epoch 506/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2663\n",
      "Epoch 507/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2661\n",
      "Epoch 508/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2663\n",
      "Epoch 509/600\n",
      "500/500 [==============================] - 1s - loss: 0.1946 - val_loss: 0.2665\n",
      "Epoch 510/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2661\n",
      "Epoch 511/600\n",
      "500/500 [==============================] - 1s - loss: 0.1942 - val_loss: 0.2662\n",
      "Epoch 512/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2663\n",
      "Epoch 513/600\n",
      "500/500 [==============================] - 2s - loss: 0.1943 - val_loss: 0.2662\n",
      "Epoch 514/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2661\n",
      "Epoch 515/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2662\n",
      "Epoch 516/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2660\n",
      "Epoch 517/600\n",
      "500/500 [==============================] - 2s - loss: 0.1942 - val_loss: 0.2663\n",
      "Epoch 518/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2662\n",
      "Epoch 519/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2661\n",
      "Epoch 520/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2661\n",
      "Epoch 521/600\n",
      "500/500 [==============================] - 2s - loss: 0.1942 - val_loss: 0.2661\n",
      "Epoch 522/600\n",
      "500/500 [==============================] - 2s - loss: 0.1940 - val_loss: 0.2662\n",
      "Epoch 523/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2662\n",
      "Epoch 524/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2661\n",
      "Epoch 525/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2663\n",
      "Epoch 526/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2663\n",
      "Epoch 527/600\n",
      "500/500 [==============================] - 1s - loss: 0.1945 - val_loss: 0.2662\n",
      "Epoch 528/600\n",
      "500/500 [==============================] - 2s - loss: 0.1943 - val_loss: 0.2661\n",
      "Epoch 529/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2662\n",
      "Epoch 530/600\n",
      "500/500 [==============================] - 2s - loss: 0.1943 - val_loss: 0.2662\n",
      "Epoch 531/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2661\n",
      "Epoch 532/600\n",
      "500/500 [==============================] - 1s - loss: 0.1939 - val_loss: 0.2660\n",
      "Epoch 533/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2661\n",
      "Epoch 534/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2660\n",
      "Epoch 535/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2663\n",
      "Epoch 536/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2662\n",
      "Epoch 537/600\n",
      "500/500 [==============================] - 1s - loss: 0.1944 - val_loss: 0.2660\n",
      "Epoch 538/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2660\n",
      "Epoch 539/600\n",
      "500/500 [==============================] - 2s - loss: 0.1944 - val_loss: 0.2660\n",
      "Epoch 540/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2661\n",
      "Epoch 541/600\n",
      "500/500 [==============================] - 2s - loss: 0.1943 - val_loss: 0.2660\n",
      "Epoch 542/600\n",
      "500/500 [==============================] - 2s - loss: 0.1940 - val_loss: 0.2660\n",
      "Epoch 543/600\n",
      "500/500 [==============================] - 2s - loss: 0.1940 - val_loss: 0.2662\n",
      "Epoch 544/600\n",
      "500/500 [==============================] - 2s - loss: 0.1942 - val_loss: 0.2660\n",
      "Epoch 545/600\n",
      "500/500 [==============================] - 2s - loss: 0.1942 - val_loss: 0.2663\n",
      "Epoch 546/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2659\n",
      "Epoch 547/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2659\n",
      "Epoch 548/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2660\n",
      "Epoch 549/600\n",
      "500/500 [==============================] - 2s - loss: 0.1942 - val_loss: 0.2660\n",
      "Epoch 550/600\n",
      "500/500 [==============================] - 1s - loss: 0.1942 - val_loss: 0.2661\n",
      "Epoch 551/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2660\n",
      "Epoch 552/600\n",
      "500/500 [==============================] - 1s - loss: 0.1937 - val_loss: 0.2658\n",
      "Epoch 553/600\n",
      "500/500 [==============================] - 1s - loss: 0.1938 - val_loss: 0.2660\n",
      "Epoch 554/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2659\n",
      "Epoch 555/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2660\n",
      "Epoch 556/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2659\n",
      "Epoch 557/600\n",
      "500/500 [==============================] - 2s - loss: 0.1937 - val_loss: 0.2659\n",
      "Epoch 558/600\n",
      "500/500 [==============================] - 1s - loss: 0.1943 - val_loss: 0.2661\n",
      "Epoch 559/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2660\n",
      "Epoch 560/600\n",
      "500/500 [==============================] - 2s - loss: 0.1937 - val_loss: 0.2659\n",
      "Epoch 561/600\n",
      "500/500 [==============================] - 2s - loss: 0.1940 - val_loss: 0.2661\n",
      "Epoch 562/600\n",
      "500/500 [==============================] - 2s - loss: 0.1939 - val_loss: 0.2658\n",
      "Epoch 563/600\n",
      "500/500 [==============================] - 2s - loss: 0.1938 - val_loss: 0.2658\n",
      "Epoch 564/600\n",
      "500/500 [==============================] - 1s - loss: 0.1940 - val_loss: 0.2660\n",
      "Epoch 565/600\n",
      "500/500 [==============================] - 1s - loss: 0.1942 - val_loss: 0.2662\n",
      "Epoch 566/600\n",
      "500/500 [==============================] - 2s - loss: 0.1939 - val_loss: 0.2660\n",
      "Epoch 567/600\n",
      "500/500 [==============================] - 2s - loss: 0.1940 - val_loss: 0.2659\n",
      "Epoch 568/600\n",
      "500/500 [==============================] - 2s - loss: 0.1940 - val_loss: 0.2660\n",
      "Epoch 569/600\n",
      "500/500 [==============================] - 2s - loss: 0.1940 - val_loss: 0.2658\n",
      "Epoch 570/600\n",
      "500/500 [==============================] - 2s - loss: 0.1938 - val_loss: 0.2658\n",
      "Epoch 571/600\n",
      "500/500 [==============================] - 2s - loss: 0.1939 - val_loss: 0.2661\n",
      "Epoch 572/600\n",
      "500/500 [==============================] - 2s - loss: 0.1942 - val_loss: 0.2659\n",
      "Epoch 573/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2662\n",
      "Epoch 574/600\n",
      "500/500 [==============================] - 1s - loss: 0.1942 - val_loss: 0.2661\n",
      "Epoch 575/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2658\n",
      "Epoch 576/600\n",
      "500/500 [==============================] - 2s - loss: 0.1939 - val_loss: 0.2659\n",
      "Epoch 577/600\n",
      "500/500 [==============================] - 2s - loss: 0.1939 - val_loss: 0.2658\n",
      "Epoch 578/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2659\n",
      "Epoch 579/600\n",
      "500/500 [==============================] - 1s - loss: 0.1940 - val_loss: 0.2660\n",
      "Epoch 580/600\n",
      "500/500 [==============================] - 2s - loss: 0.1938 - val_loss: 0.2657\n",
      "Epoch 581/600\n",
      "500/500 [==============================] - 1s - loss: 0.1937 - val_loss: 0.2658\n",
      "Epoch 582/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2658\n",
      "Epoch 583/600\n",
      "500/500 [==============================] - 2s - loss: 0.1937 - val_loss: 0.2658\n",
      "Epoch 584/600\n",
      "500/500 [==============================] - 1s - loss: 0.1938 - val_loss: 0.2660\n",
      "Epoch 585/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2659\n",
      "Epoch 586/600\n",
      "500/500 [==============================] - 1s - loss: 0.1939 - val_loss: 0.2659\n",
      "Epoch 587/600\n",
      "500/500 [==============================] - 1s - loss: 0.1938 - val_loss: 0.2659\n",
      "Epoch 588/600\n",
      "500/500 [==============================] - 1s - loss: 0.1938 - val_loss: 0.2658\n",
      "Epoch 589/600\n",
      "500/500 [==============================] - 1s - loss: 0.1940 - val_loss: 0.2661\n",
      "Epoch 590/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2659\n",
      "Epoch 591/600\n",
      "500/500 [==============================] - 1s - loss: 0.1941 - val_loss: 0.2659\n",
      "Epoch 592/600\n",
      "500/500 [==============================] - 2s - loss: 0.1938 - val_loss: 0.2660\n",
      "Epoch 593/600\n",
      "500/500 [==============================] - 2s - loss: 0.1941 - val_loss: 0.2661\n",
      "Epoch 594/600\n",
      "500/500 [==============================] - 2s - loss: 0.1937 - val_loss: 0.2657\n",
      "Epoch 595/600\n",
      "500/500 [==============================] - 1s - loss: 0.1936 - val_loss: 0.2659\n",
      "Epoch 596/600\n",
      "500/500 [==============================] - 1s - loss: 0.1939 - val_loss: 0.2659\n",
      "Epoch 597/600\n",
      "500/500 [==============================] - 1s - loss: 0.1940 - val_loss: 0.2660\n",
      "Epoch 598/600\n",
      "500/500 [==============================] - 1s - loss: 0.1940 - val_loss: 0.2660\n",
      "Epoch 599/600\n",
      "500/500 [==============================] - 1s - loss: 0.1936 - val_loss: 0.2657\n",
      "Epoch 600/600\n",
      "500/500 [==============================] - 1s - loss: 0.1935 - val_loss: 0.2658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e66cc47518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=600,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/8AAADqCAYAAAD08fXjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAGDg/D/hAFQnHYPkpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6dbc256a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in [1,2,3,4,5,6,7,8,9]:\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
